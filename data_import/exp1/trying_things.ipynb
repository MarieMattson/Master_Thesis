{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from datasets  import load_dataset\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from ragas.testset import TestsetGenerator\n",
    "from langchain.schema import Document\n",
    "\n",
    "load_dotenv()\n",
    "#OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "#N_GENERATIONS = 5  # Generate only 5 QA pairs for cost and time considerations\n",
    "#dataset = load_dataset(\"json\", data_files=\"/mnt/c/Users/User/thesis/data_import/exp1/even_more_filtered_riksdag.json\", split=\"train\")\n",
    "#dataset = dataset.filter(lambda x: x[\"dok_id\"] in [\"H90968\", \"H90982\"])\n",
    "#url = \"https://api.openai.com/v1/chat/completions\"\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "\n",
    "path = \"/mnt/c/Users/User/thesis/data_import/exp1/testing_riksdag_data/filtered_riksdag_exp1.json\"\n",
    "#loader = DirectoryLoader(path, glob=\"**/*.md\")\n",
    "#docs = loader.load()\n",
    "\n",
    "#Â¤dataset = load_dataset(\"json\", data_files=path, split=\"train\")\n",
    "#docs = [Document(page_content=doc[\"anforandetext\"], metadata={\"source\": doc.get(\"dok_titel\", \"unknown\")})for doc in dataset]\n",
    "\n",
    "#dataset = generator.generate_with_langchain_docs(docs, testset_size=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66429a6ab8a4b10937ab7ba6113b017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b983c6fcebf54e8891f52036274554a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e113d09d101a44fdad54b228a024fc09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary' already exists in node '73c09a'. Skipping!\n",
      "Property 'summary' already exists in node 'ba7263'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e4d83d68fe4e6d98641ae2317975bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0374ab536dfe480eb911d61d701c3a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary_embedding' already exists in node 'ba7263'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '73c09a'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8e86ffd73240b1b1d72bc42140dd44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee7427ed32f24d50b4ba46fa97730f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688ffbd37f794c2b92ea9dc9e25ca7ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70ea3dd8d7e4f3c9c3856a2612ceec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9cb6ad843214be3a3d2d9c5ccc13b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edbf3766cf2f424ba397232721d33aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary' already exists in node '1eb8fb'. Skipping!\n",
      "Property 'summary' already exists in node '6fd1d6'. Skipping!\n",
      "Property 'summary' already exists in node 'ab3a79'. Skipping!\n",
      "Property 'summary' already exists in node '47e065'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b173560a322436a8dbec5e46f2d5eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a145598137eb4dc29ca5cd94e6ea2f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary_embedding' already exists in node 'ab3a79'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '6fd1d6'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '47e065'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '1eb8fb'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d450b54994424d942f3a82ecfe915f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9356b6404e22401695d212ec12f45670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac26667ba29489eaf6f71022a814262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42397d5cccfb4feba7f519bca1c13f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e9019f78344cbcb816e09058b033e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to apply transformation: 'headlines' property not found in this node\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb1e14d529b4a7e86d3557de151e09b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary' already exists in node '720089'. Skipping!\n",
      "Property 'summary' already exists in node '6facfe'. Skipping!\n",
      "Property 'summary' already exists in node '4e8f70'. Skipping!\n",
      "Property 'summary' already exists in node 'ac05b1'. Skipping!\n",
      "Property 'summary' already exists in node '6b93ca'. Skipping!\n",
      "Property 'summary' already exists in node 'e0a371'. Skipping!\n",
      "Property 'summary' already exists in node 'efe4d8'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "139a0e2fcb824b6b87263d9485eb20b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffbb0c86d15b4388a62722b8534aaa8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-757' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29265, Requested 1392. Please try again in 1.314s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29265, Requested 1392. Please try again in 1.314s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-732' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29021, Requested 2132. Please try again in 2.306s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29021, Requested 2132. Please try again in 2.306s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-731' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29005, Requested 2299. Please try again in 2.608s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29005, Requested 2299. Please try again in 2.608s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-727' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29552, Requested 2146. Please try again in 3.396s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29552, Requested 2146. Please try again in 3.396s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-725' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29478, Requested 2574. Please try again in 4.104s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29478, Requested 2574. Please try again in 4.104s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-723' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29043, Requested 2035. Please try again in 2.156s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29043, Requested 2035. Please try again in 2.156s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-720' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29819, Requested 1996. Please try again in 3.63s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29819, Requested 1996. Please try again in 3.63s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-708' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29287, Requested 1873. Please try again in 2.32s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29287, Requested 1873. Please try again in 2.32s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-707' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 28971, Requested 2185. Please try again in 2.312s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 28971, Requested 2185. Please try again in 2.312s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-702' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29809, Requested 2296. Please try again in 4.21s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29809, Requested 2296. Please try again in 4.21s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-681' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29008, Requested 2708. Please try again in 3.432s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29008, Requested 2708. Please try again in 3.432s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-669' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 28943, Requested 3091. Please try again in 4.068s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 28943, Requested 3091. Please try again in 4.068s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-659' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29648, Requested 2565. Please try again in 4.426s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29648, Requested 2565. Please try again in 4.426s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-658' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29799, Requested 2455. Please try again in 4.508s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29799, Requested 2455. Please try again in 4.508s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-655' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29746, Requested 2463. Please try again in 4.418s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29746, Requested 2463. Please try again in 4.418s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-653' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29586, Requested 2913. Please try again in 4.998s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29586, Requested 2913. Please try again in 4.998s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-652' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 28190, Requested 2545. Please try again in 1.47s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 28190, Requested 2545. Please try again in 1.47s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-646' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29187, Requested 2773. Please try again in 3.919s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29187, Requested 2773. Please try again in 3.919s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-635' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 28783, Requested 2581. Please try again in 2.728s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 28783, Requested 2581. Please try again in 2.728s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-634' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 28848, Requested 2567. Please try again in 2.83s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 28848, Requested 2567. Please try again in 2.83s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-633' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29706, Requested 3539. Please try again in 6.49s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29706, Requested 3539. Please try again in 6.49s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-631' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29863, Requested 3097. Please try again in 5.92s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 29863, Requested 3097. Please try again in 5.92s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-629' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 28519, Requested 2449. Please try again in 1.936s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 28519, Requested 2449. Please try again in 1.936s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-622' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 27656, Requested 3232. Please try again in 1.776s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 27656, Requested 3232. Please try again in 1.776s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-621' coro=<as_completed.<locals>.sema_coro() done, defined at /mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 28979, Requested 2643. Please try again in 3.244s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
      "    property_name, property_value = await self.extract(node)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 264, in extract\n",
      "    result = await self.prompt.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/user/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 825, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1843, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1537, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1623, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1638, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-KyNUQSd5ttRozjQ1KNAlvD5T on tokens per min (TPM): Limit 30000, Used 28979, Requested 2643. Please try again in 3.244s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Property 'summary_embedding' already exists in node '4e8f70'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '6facfe'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'ac05b1'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '6b93ca'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'e0a371'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'efe4d8'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '720089'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8fa03d1f484f568d34a2dffda1e0a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5063f80e4abb46aba9825ef05bb0b545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff831ff942c4fa09ad92923924c7e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3844c614de243cdb4e5639264c0e6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b6ee3869be4c43926036fdf17a5da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f22cd6d79b4e898e43c0058e8588b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary' already exists in node '303933'. Skipping!\n",
      "Property 'summary' already exists in node 'ec6e9f'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8952cf6ed725423bab395074bdc3b604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72bcef8120834ced93f4c2c739e4f08b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary_embedding' already exists in node 'ec6e9f'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '303933'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1036f82ecb73437dad91ee063997d37f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed568fed6e7430cb139b33bfcdb2792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a048bc044d141dca51d02b2353004a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(data_list), CHUNK_SIZE):\n\u001b[32m     34\u001b[39m     chunk = data_list[i : i + CHUNK_SIZE]\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     processed_docs = \u001b[43mprocess_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     \u001b[38;5;66;03m# Save results as JSON (appending to file)\u001b[39;00m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m processed_docs:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mprocess_chunk\u001b[39m\u001b[34m(chunk)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess_chunk\u001b[39m(chunk):\n\u001b[32m      8\u001b[39m     docs = [\n\u001b[32m      9\u001b[39m         Document(\n\u001b[32m     10\u001b[39m             page_content=doc[\u001b[33m\"\u001b[39m\u001b[33manforandetext\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m chunk\n\u001b[32m     14\u001b[39m     ]\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     processed_data = \u001b[43mgenerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_with_langchain_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestset_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [serialize_object(item) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m processed_data]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/synthesizers/generate.py:188\u001b[39m, in \u001b[36mTestsetGenerator.generate_with_langchain_docs\u001b[39m\u001b[34m(self, documents, testset_size, transforms, transforms_llm, transforms_embedding_model, query_distribution, run_config, callbacks, with_debugging_logs, raise_exceptions)\u001b[39m\n\u001b[32m    185\u001b[39m apply_transforms(kg, transforms)\n\u001b[32m    186\u001b[39m \u001b[38;5;28mself\u001b[39m.knowledge_graph = kg\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtestset_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtestset_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_distribution\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_distribution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwith_debugging_logs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwith_debugging_logs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/testset/synthesizers/generate.py:448\u001b[39m, in \u001b[36mTestsetGenerator.generate\u001b[39m\u001b[34m(self, testset_size, query_distribution, num_personas, run_config, batch_size, callbacks, token_usage_parser, with_debugging_logs, raise_exceptions)\u001b[39m\n\u001b[32m    441\u001b[39m         additional_testset_info.append(\n\u001b[32m    442\u001b[39m             {\n\u001b[32m    443\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33msynthesizer_name\u001b[39m\u001b[33m\"\u001b[39m: synthesizer.name,\n\u001b[32m    444\u001b[39m             }\n\u001b[32m    445\u001b[39m         )\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m448\u001b[39m     eval_samples = \u001b[43mexec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    450\u001b[39m     sample_generation_rm.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/ragas/executor.py:213\u001b[39m, in \u001b[36mExecutor.results\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    210\u001b[39m             nest_asyncio.apply()\n\u001b[32m    211\u001b[39m             \u001b[38;5;28mself\u001b[39m._nest_asyncio_applied = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m results = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_jobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m sorted_results = \u001b[38;5;28msorted\u001b[39m(results, key=\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m0\u001b[39m])\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [r[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m sorted_results]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/nest_asyncio.py:92\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     90\u001b[39m     f._log_destroy_pending = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping:\n\u001b[32m     94\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/User/thesis/.venv/lib/python3.12/site-packages/nest_asyncio.py:115\u001b[39m, in \u001b[36m_patch_loop.<locals>._run_once\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    108\u001b[39m     heappop(scheduled)\n\u001b[32m    110\u001b[39m timeout = (\n\u001b[32m    111\u001b[39m     \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[32m    113\u001b[39m         scheduled[\u001b[32m0\u001b[39m]._when - \u001b[38;5;28mself\u001b[39m.time(), \u001b[32m0\u001b[39m), \u001b[32m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m._process_events(event_list)\n\u001b[32m    118\u001b[39m end_time = \u001b[38;5;28mself\u001b[39m.time() + \u001b[38;5;28mself\u001b[39m._clock_resolution\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/selectors.py:468\u001b[39m, in \u001b[36mEpollSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    466\u001b[39m ready = []\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m468\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    470\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "output_path = \"/mnt/c/Users/User/thesis/data_import/exp1/generated_testset_2.json\"\n",
    "dataset = load_dataset(\"json\", data_files=path, split=\"train\")\n",
    "data_list = [doc for doc in dataset]\n",
    "\n",
    "CHUNK_SIZE = 10  # Process 10 documents at a time\n",
    "\n",
    "def process_chunk(chunk):\n",
    "    docs = [\n",
    "        Document(\n",
    "            page_content=doc[\"anforandetext\"],\n",
    "            metadata={\"source\": doc.get(\"dok_id\", \"unknown\")}\n",
    "        )\n",
    "        for doc in chunk\n",
    "    ]\n",
    "    processed_data = generator.generate_with_langchain_docs(docs, testset_size=10)\n",
    "    return [serialize_object(item) for item in processed_data]\n",
    "\n",
    "\n",
    "def serialize_object(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {key: serialize_object(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [serialize_object(item) for item in obj]\n",
    "    elif hasattr(obj, \"__dict__\"):\n",
    "        return serialize_object(obj.__dict__)  # Recursively convert __dict__\n",
    "    elif isinstance(obj, (str, int, float, bool, type(None))):\n",
    "        return obj  # Primitive types are JSON serializable\n",
    "    else:\n",
    "        return str(obj)  # Fallback for unknown types\n",
    "\n",
    "\n",
    "with open(output_path, \"a\", encoding=\"utf-8\") as f:\n",
    "    for i in range(0, len(data_list), CHUNK_SIZE):\n",
    "        chunk = data_list[i : i + CHUNK_SIZE]\n",
    "        processed_docs = process_chunk(chunk)\n",
    "        \n",
    "        # Save results as JSON (appending to file)\n",
    "        for item in processed_docs:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "        \n",
    "        # Avoid hitting rate limits\n",
    "        time.sleep(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to /mnt/c/Users/User/thesis/data_import/exp1/generated_testset_2.json\n"
     ]
    }
   ],
   "source": [
    "output_path = \"/mnt/c/Users/User/thesis/data_import/exp1/generated_testset_2.json\"\n",
    "dataset = dataset.to_list()  # Ensure Testset has this method\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(dataset, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"Dataset saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
